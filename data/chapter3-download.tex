% \begingroup
% \let\clearpage\relax
% \chapter{实验与分析}

% % \section{创新思想和学术贡献}

% % 在本文中，本文提出了一种基于凸基学习器的元学习方法用于少样本学习。
% % 对偶形式和KKT条件可用于实现计算和存储效率高的元学习，因此特别适用于少样本学习问题。
% % 与最近邻分类器相比，线性分类器在稍微增加计算成本的情况下提供更好的泛化能力。
% % 本文的实验表明，正则化的线性模型允许更高的嵌入维度，并减少了过度拟合。对于未来的工作，
% % 本文旨在探索其他凸基学习器，如核SVM。这将允许随着更多的训练数据可用于任务而逐渐增加模型容量的能力。

% % \section{实验方法}
% % 首先，本文描述了在实验中使用的网络架构和优化细节。
% % 然后，本文展示了在标准的几种少样本分类基准上的结果，包括ImageNet的派生数据集和CIFAR，
% % 随后本文使用相同的嵌入网络和训练设置对各种基础学习器对准确性和速度的影响进行了详细分析。
% \section{实验设置}
% 在元学习设置方面，本文在实验中使用了一个ResNet-12网络，遵循\upcite{oreshkin2018tadam,mishra2017simple}。
% 令Rk表示由三个{3×3卷积和k个滤波器，批归一化，Leaky ReLU(0.1)}组成的残差块；令MP表示2×2最大池化。本文使用了DropBlock正则化\upcite{ghiasi2018dropblock}，
% 一种结构化Dropout形式。令DB(k，b)表示具有保持率为k和块大小为b的DropBlock层。
% 用于ImageNet衍生数据集的网络架构为：R64-MP-DB(0.9,1)-R160-MP-DB(0.9,1)-R320-MP-DB(0.9,5)-R640-MP-DB(0.9,5)，
% 而用于CIFAR衍生数据集的网络架构为：R64-MP-DB(0.9,1)-R160-MP-DB(0.9,1)-R320-MP-DB(0.9,2)-R640-MP-DB(0.9,2)。

% 本文使用带有0.9的Nesterov动量和0.0005的权重衰减的SGD作为优化器。
% 该模型进行了60个epochs的元训练，每个epoch包含1000个样本集。
% 学习率最初设置为0.1，然后在第20、40和50个epoch时分别更改为0.006、0.0012和0.00024，这是遵循\upcite{gidaris2018dynamic}的实践。

% 在元训练期间，本文采用了水平翻转、随机裁剪和颜色（亮度、对比度和饱和度）扰动数据增强，如\upcite{gidaris2018dynamic,qiao2018few}中所述。
% 本文在两个阶段都使用5路分类，这是遵循最近的工作\upcite{gidaris2018dynamic,oreshkin2018tadam}。每个类别在元训练期间包含6个测试（查询）样本，
% 在元测试期间包含15个测试样本。本文的元训练模型是基于元验证集上5路5-shot测试准确性选择的。

% 对于原型网络，本文将元训练shot设置为与元测试shot相匹配，这是遵循\upcite{snell2017prototypical,gidaris2018dynamic}的做法。
% 对于SVM和岭回归，本文观察到保持元训练shot高于元测试shot可以获得更好的测试准确性，如 图\ref{fig:2} 所示。因此，在元训练期间，
% 本文针对ResNet-12的miniImageNet将训练shot设置为15；对于使用4层CNN的miniImageNet（在表\ref{table:3}中）将训练shot设置为5；
% 对于tieredImageNet，将训练shot设置为10；对于CIFAR-FS，将训练shot设置为5；对于FC100，将训练shot设置为15。

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=.7\linewidth]{figure/f2.png}
%     \caption{使用不同的元训练样本数量，在miniImageNet元测试集上的测试准确率（\%）。}
%     \label{fig:2}
% \end{figure}

% % 在基学习器的设置方面，对于线性分类器的训练，本文使用二次规划求解器OptNet \upcite{amos2017optnet}。
% % SVM的正则化参数C设置为0.1。岭回归的正则化参数λ设置为50.0。对于最近类均值（原型网络），
% % 本文使用针对特征维度进行归一化的平方欧氏距离。

% % 在提前停止方面，虽然本文可以运行优化器直到收敛，但在实践中，本文发现在固定的迭代次数（仅三次）
% % 内运行QP求解器实际上效果很好。提前停止起到了额外的正则化作用，甚至可以带来稍微更好的性能。


% \subsection{在ImageNet的衍生数据集上的实验}

% miniImageNet数据集\upcite{vinyals2016matching}是用于少样本图像分类的标准基准测试，
% 由ILSVRC-2012 \upcite{russakovsky2015imagenet}中随机选择的100个类组成。
% tieredImageNet基准测试\upcite{ren2018meta}是ILSVRC-2012 \upcite{russakovsky2015imagenet}的一个较大子集，由608个类别组成，分为34个高级类别。

% 表\ref{table:1}总结了5-way miniImageNet和tieredImageNet上的结果。在miniImageNet和tieredImageNet元测试集上，
% 使用95\%置信区间的平均few-shot分类准确率（\%）。“a-b-c-d”表示每个层中具有a，b，c和d个滤波器的4层卷积网络。
% †表示使用元训练集和元验证集的并集来元训练元学习器。“RR”代表岭回归。
% \begin{table}[htbp]
%     \caption{与之前在miniImageNet和tieredImageNet上的工作进行比较}
%     \resizebox{\linewidth}{!}{  
%     \begin{tabular}{
%     l 
%     l 
%     c 
%     c 
%     l 
%     l }
%     \toprule 
%                                                      &                                   & \multicolumn{2}{c}{\textbf{miniImageNet 5-way}}                                                               & \multicolumn{2}{c}{\textbf{tieredImageNet 5-way}}                                                 \\ \cline{3-6} 
%     \textbf{model}                                   & \textbf{backbone}                 & \textbf{1-shot}                                                   & \textbf{5-shot}                                                   & \multicolumn{1}{c}{\textbf{1-shot}} & \multicolumn{1}{c}{\textbf{5-shot}} \\ \hline
%     Meta-Learning LSTM*                              & 64-64-64-64                       & 43.44 ± 0.77                                                      & 60.60 ± 0.71                                                      & -                                                           & -                                                           \\
%     Matching Networks*                               & 64-64-64-64                       & 43.56 ± 0.84                                                      & 55.31 ± 0.73                                                      & -                                   & -                                   \\
%     MAML                                             & 32-32-32-32                       & 48.70 ± 1.84                                                      & 63.11 ± 0.92                                                      & 51.67 ± 1.81                                                & 70.30 ± 1.75                                                \\
%     Prototypical Networks*                           & 64-64-64-64                       & 49.42 ± 0.78                                                      & 68.20 ± 0.66                                                      & 53.31 ± 0.89                                                & 72.69 ± 0.74                                                \\
%     Relation Networks*                               & 64-96-128-256                     & 50.44 ± 0.82                                                      & 65.32 ± 0.70                                                      & 54.48 ± 0.93                                                & 71.32 ± 0.78                                                \\
%     R2D2                                             & 96-192-384-512                    & 51.2 ± 0.6                                                        & 68.8 ± 0.1                                                        & -                                   & -                                   \\
%     Transductive Prop Nets                           & 64-64-64-64                       & 55.51 ± 0.86                                                      & 69.86 ± 0.65                                                      & 59.91 ± 0.94                                                & 73.30 ± 0.75                                                \\
%     SNAIL                                            & ResNet-12                         & 55.71 ± 0.99                                                      & 68.88 ± 0.92                                                      & -                                   & -                                   \\
%     Dynamic Few-shot                                 & 64-64-128-128                     & 56.20 ± 0.86                                                      & 73.00 ± 0.64                                                      & -                                   & -                                   \\
%     AdaResNet                                        & ResNet-12                         & 56.88 ± 0.62                                                      & 71.94 ± 0.57                                                      & -                                   & -                                   \\
%     TADAM                                            & ResNet-12                         & 58.50 ± 0.30                                                      & 76.70 ± 0.30                                                      & -             -                                   \\
%     Activation to Parameter† & WRN-28-10                         & 59.60 ± 0.41                                                      & 73.74 ± 0.19                                                      & -                                   & -                                   \\
%     LEO                                              & WRN-28-10                         & 61.76 ± 0.08                                                      & 77.59 ± 0.12                                                      & 66.33 ± 0.05                                                & 81.44 ± 0.09                                                \\
%     MetaOptNet-RR (ours)                             & ResNet-12 & 61.41 ± 0.61                                                      & 77.88 ± 0.46                                                      & \textbf{65.36 ± 0.71}                                       & \textbf{81.34 ± 0.52}                                       \\
%     MetaOptNet-SVM (ours)                            & ResNet-12                         & 62.64 ± 0.61                                                      & 78.63 ± 0.46                                                      & \textbf{65.99 ± 0.72}                                       & \textbf{81.56 ± 0.53}                                       \\
%     MetaOptNet-SVM-trainval (ours)†                  & ResNet-12                         & \textbf{64.09 ± 0.62} & \textbf{80.00 ± 0.45} & \textbf{65.81 ± 0.74}                                       & \textbf{81.75 ± 0.53}                                       \\
%     \bottomrule
%     \end{tabular}
%     }
%     \label{table:1}
% \end{table}
% 本文的方法在5-way miniImageNet和tieredImageNet基准测试上取得了最先进的性能。
% % 需要注意的是，LEO \upcite{rusu2018meta}除了使用WRN-28-10主干网络外，还利用编码器和关系网络来产生梯度下降的样本相关初始化。
% % TADAM \upcite{oreshkin2018tadam}为每个卷积层使用任务嵌入网络(TEN)块，用于预测元素级比例和偏移向量。

% % 本文还注意到，\upcite{rusu2018meta,qiao2018few}对WRN-28-10特征提取器\upcite{zagoruyko2016wide}进行了预训练，以共同分类miniImageNet元训练集中的全部64个类别；然后在元训练期间冻结网络。
% % \upcite{oreshkin2018tadam}使用了一种类似的策略，使用标准分类任务：他们同时在few-shot分类任务(5-way)和标准分类任务(64-way)上联合训练特征嵌入。
% % 相比之下，
% % 本文的系统是端到端进行元训练的，明确地训练特征提取器在带有正则化线性分类器的few-shot学习任务上表现良好。

% \subsection{CIFAR派生数据集的实验}

% CIFAR-FS数据集\upcite{bertinetto2018meta}是最近提出的few-shot图像分类基准测试，
% 由CIFAR-100 \upcite{krizhevsky2010cifar}中的全部100个类别组成。
% FC100数据集\upcite{oreshkin2018tadam}是另一个源自CIFAR-100 \upcite{krizhevsky2010cifar}的数据集，包含100个类别，这些类别被分成20个超类。

% 表\ref{table:2}总结了5-way分类任务的结果，本文的MetaOptNet-SVM方法实现了最先进的性能。

% \begin{table}[htbp]
%     \caption{在不同的元训练样本量下，CIFAR-FS 和 FC100元测试集的测试准确率（以百分比表示）}
%     \resizebox{\linewidth}{!}{  
%     \begin{tabular}{llcccc}
%     \hline
%                                     &                   & \multicolumn{2}{c}{\textbf{CIFAR-FS 5-way}} & \multicolumn{2}{c}{\textbf{FC100 5-way}}                      \\ \hline
%     \textbf{model}                  & \textbf{backbone} & \textbf{1-shot}      & \textbf{5-shot}      & \textbf{1-shot}     & \textbf{5-shot}                         \\ \hline
%     MAML*                           & 32-32-32-32       & 58.9 ± 1.9           & 71.5 ± 1.0           & -                   & -                                       \\
%     Prototypical Networks*†         & 64-64-64-64       & 55.5 ± 0.7           & 72.0 ± 0.6           & 35.3 ± 0.6          & 48.6 ± 0.6                              \\
%     Relation Networks*              & 64-96-128-256     & 55.0 ± 1.0           & 69.3 ± 0.8           & -                   & -                                       \\
%     R2D2                            & 96-192-384-512    & 65.3 ± 0.2           & 79.4 ± 0.1           & -                   & -                                       \\
%     TADAM                           & ResNet-12         & -                    & -                    & 40.1 ± 0.4          & 56.1 ± 0.4                              \\
%     ProtoNets (our backbone)        & ResNet-12         & \textbf{72.2 ± 0.7}  & 83.5 ± 0.5           & 37.5 ± 0.6          & 52.5 ± 0.6                              \\
%     MetaOptNet-RR (ours)            & ResNet-12         & \textbf{72.6 ± 0.7}  & \textbf{84.3 ± 0.5}  & 40.5 ± 0.6          & 55.3 ± 0.6                              \\
%     MetaOptNet-SVM (ours)           & ResNet-12         & \textbf{72.0 ± 0.7}  & \textbf{84.2 ± 0.5}  & 41.1 ± 0.6          & 55.5 ± 0.6                              \\
%     MetaOptNet-SVM-trainval (ours) & ResNet-12         & \textbf{72.8 ± 0.7}  & \textbf{85.0 ± 0.5}  & \textbf{47.2 ± 0.6} & \multicolumn{1}{l}{\textbf{62.5 ± 0.6}} \\ \hline
%     \end{tabular}
%     }
%     \label{table:2}
% \end{table}

% \section{实验结果比较}

% 表\ref{table:3}显示了本文改变两种不同嵌入架构的基学习器后的结果。当本文使用标准的4层卷积网络，特征维度较低（1600）时，
% 本文没有观察到采用判别式分类器对few-shot学习的实质性益处。事实上，最近邻类均值分类器\upcite{mensink2013distance}在低维特征下表现良好，
% 如Prototypical Networks\upcite{sung2018learning}所示。
% 然而，当嵌入维度远高于16000时，SVM比其他基学习器产生更好的few-shot准确性。因此，当高维特征可用时，正则化线性分类器提供了鲁棒性。

% \begin{table}[htbp]
%     \caption{基础学习器和嵌入网络架构的影响}
%     \resizebox{\linewidth}{!}{  
%     \begin{tabular}{lcccccccc}
%     \hline
%                           & \multicolumn{4}{c}{\textbf{miniImageNet 5-way}}                                    & \multicolumn{4}{c}{\textbf{tieredImageNet 5-way}}                                 \\ \cline{2-9} 
%                           & \multicolumn{2}{c}{\textbf{1-shot}}      & \multicolumn{2}{c}{\textbf{5-shot}}     & \multicolumn{2}{c}{\textbf{1-shot}}     & \multicolumn{2}{c}{\textbf{5-shot}}     \\
%     \textbf{model}        & \textbf{acc. (\%)}  & \textbf{time (ms)} & \textbf{acc. (\%)}  & \textbf{ime (ms)} & \textbf{acc. (\%)}  & \textbf{ime (ms)} & \textbf{acc. (\%)}  & \textbf{ime (ms)} \\ \hline
%     \multicolumn{9}{l}{\textbf{4-layer conv (feature dimension=1600)}}                                                                                                                             \\
%     Prototypical Networks & 53.47±0.63          & 6±0.01             & 70.68±0.49          & 7±0.02            & 54.28±0.67          & 6±0.03            & 71.42±0.61          & 7±0.02            \\
%     MetaOptNet-RR (ours)  & 53.23±0.59          & 20±0.03            & 69.51±0.48          & 27±0.05           & 54.63±0.67          & 21±0.05           & 72.11±0.59          & 28±0.06           \\
%     MetaOptNet-SVM (ours) & 52.87±0.57          & 28±0.02            & 68.76±0.48          & 37±0.05           & 54.71±0.67          & 28±0.07           & 71.79±0.59          & 38±0.08           \\ \hline
%     \multicolumn{9}{l}{\textbf{ResNet-12 (feature dimension=16000)}}                                                                                                                               \\
%     Prototypical Networks & 59.25±0.64          & 60±17              & 75.60±0.48          & 66±17             & 61.74±0.77          & 61±17             & 80.00±0.55          & 66±18             \\
%     MetaOptNet-RR (ours)  & 61.41±0.61          & 68±17              & \textbf{77.88±0.46} & 75±17             & \textbf{65.36±0.71} & 69±17             & \textbf{81.34±0.52} & 77±17             \\
%     MetaOptNet-SVM (ours) & \textbf{62.64±0.61} & 78±17              & \textbf{78.63±0.46} & 89±17             & \textbf{65.99±0.72} & 78±17             & \textbf{81.56±0.53} & 90±17             \\ \hline
%     \end{tabular}
%     }
%     \label{table:3}
%     \end{table}

% % 这种方法的额外好处是计算成本的适度增加。
% 对于ResNet-12，与最近类平均分类器相比，岭回归基学习器的额外开销约为13％，
% SVM基学习器的额外开销约为30-50％。从图\ref{fig:2}可以看出，本文模型的性能在1-shot和5-shot情况下通常随着meta-training shot的增加而增加。
% % 这使得该方法更加实用，因为本文可以使用高shot元训练一次嵌入来适用于所有的meta-testing shot。
% % 本文假设训练数据的类别嵌入比测试数据更紧凑\upcite{yosinski2014transferable}，基于此，基学习器的灵活性可以提高对嵌入噪声的鲁棒性并改善泛化能力。

% \section{减少元过拟合}

% % 在元训练结束时，
% % MetaOptNet-SVM与ResNet-12在除tieredImageNet外的所有元训练数据集上几乎都达到了100％的测试准确率。
% 为了缓解过拟合，类似于\upcite{rusu2018meta,qiao2018few}，本文使用元训练集和元验证集的并集来元训练嵌入，保持超参数（例如epoch数）与先前设置相同。
% 表\ref{table:1}和表\ref{table:2}显示了使用增强的元训练集（称为MetaOptNet-SVM-trainval）的结果。
% 本文的结果表明，使用更多的元训练“类”进行元学习嵌入有助于减少对元训练集的过拟合。

% 表\ref{table:4}显示了正则化方法对MetaOptNet-SVM与ResNet-12的影响。
% 本文发现如果不使用正则化，则ResNet-12的性能会降低到表\ref{table:3}中每层64个过滤器的4层卷积网络的性能水平。
% 这表明正则化对于元学习非常重要。
% % 本文期望通过引入新的正则化方法，进一步提高少样本学习系统的性能。

% \begin{table}[htbp]
%     \centering
%     \caption{消融研究}
%     \begin{tabular}{ccccc|cc}
%     \hline
%     \textbf{\begin{tabular}[c]{@{}c@{}}Data\\ Aug.\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Weight\\ Decay\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Drop\\ Block\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Label\\ Smt.\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Larger\\ Data\end{tabular}} & \textbf{1-shot} & \textbf{5-shot} \\ \hline
%                                                                  & \textbf{}                                                       & \textbf{}                                                     & \textbf{}                                                     & \textbf{}                                                      & 51.13           & 70.88           \\
%     \textbf{√}                                                   & \textbf{}                                                       & \textbf{}                                                     & \textbf{}                                                     & \textbf{}                                                      & 55.80           & 75.76           \\
%     \textbf{}                                                    & \textbf{√}                                                      &                                                               &                                                               &                                                                & 56.65           & 73.72           \\
%     \textbf{√}                                                   & \textbf{√}                                                      &                                                               &                                                               &                                                                & 60.33           & 76.61           \\
%     \textbf{√}                                                   & \textbf{√}                                                      & \textbf{√}                                                    &                                                               &                                                                & 61.11           & 77.40           \\
%     \textbf{√}                                                   & \textbf{√}                                                      & \textbf{√}                                                    & \textbf{√}                                                    &                                                                & 62.64           & 78.63           \\
%     \textbf{√}                                                   & \textbf{√}                                                      & \textbf{√}                                                    & \textbf{√}                                                    & \textbf{√}                                                     & 64.09           & 80.00           \\ \hline
%     \end{tabular}
 
%     \label{table:4}
%     \end{table}

% \section{双重优化效率}

% 为了验证双重优化确实是有效和高效的，本文在 QP 求解器的不同迭代次数下测量了元测试集上的准确性。
% % QP 求解器\upcite{amos2017optnet}的每次迭代都涉及通过 KKT 矩阵的 LU 分解计算原始变量和对偶变量的更新。
% 结果显示在图 \ref{fig:3} 中。QP 求解器在只进行一次迭代的情况下就达到了岭回归目标的最优解。
% 如\upcite{bertinetto2018meta}。此外，本文观察到对于1-shot任务，
% QP SVM求解器在1次迭代中就达到了最优准确率。
% 对于5-shot任务，即使本文只运行一次 QP SVM 求解器，本文也能获得比其他基础学习器更好的准确率。
% % 当 SVM 求解器的迭代次数限制为1次时，一个任务的执行时间为 69±17 毫秒，对于 5-shot 任务是 80±17 毫秒，
% % 这与岭回归求解器的计算成本相当(Table 3)。
% 这些实验表明，在少样本学习的情况下，解决 SVM 和岭回归的对偶目标非常有效。

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=.7\linewidth]{figure/f3.png}
%     \caption{使用不同的元训练样本数量，在miniImageNet元测试集上的测试准确率（\%）。}
%     \label{fig:3}
% \end{figure}
% \endgroup
